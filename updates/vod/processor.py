"""
OneTV-API ç‚¹æ’­æºå¤„ç†å™¨
VOD Source Processor Module
"""
import json
import os
from datetime import datetime
from typing import Dict

from utils.tools import resource_path


class VODProcessor:
    """ç‚¹æ’­æºå¤„ç†å™¨"""
    
    def __init__(self):
        self.output_dir = resource_path("vod/output")
        self.ensure_output_dir()
    
    def ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir, exist_ok=True)
    
    def generate_vod_json(self, vod_data: Dict) -> str:
        """ç”Ÿæˆç‚¹æ’­æºJSONæ–‡ä»¶ - å¤šä»“åº“æ ¼å¼"""
        valid_sources = vod_data.get("valid_sources", [])
        total_sources = vod_data.get("total_sources", 0)

        if not valid_sources:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ç‚¹æ’­æºæ•°æ®!")
            return ""

        # æŒ‰è´¨é‡è¯„åˆ†æ’åºï¼Œå–å‰30ä¸ªæœ€ä¼˜è´¨æº
        top_sources = sorted(valid_sources,
                            key=lambda x: x.get("quality_score", 0),
                            reverse=True)[:30]

        # æ„å»ºå¤šä»“åº“æ ¼å¼çš„JSONé…ç½® - å¸¦å“ç‰Œè¯†åˆ«
        multi_repo_config = {
            "storeHouse": [
                {
                    "sourceName": "OneTVå½±è§†ä»“åº“",
                    "sourceUrl": "https://raw.githubusercontent.com/HaoHaoKanYa/OneTV-API/refs/heads/main/vod/output/onetv-api-movie.json"
                }
            ],
            "urls": []
        }

        # å°†æœ‰æ•ˆæºè½¬æ¢ä¸ºå¤šä»“åº“æ ¼å¼
        for source in top_sources:
            # æ ¹æ®è´¨é‡è¯„åˆ†æ·»åŠ æ˜Ÿçº§æ ‡è¯†
            quality_score = source.get("quality_score", 0)
            if quality_score >= 95:
                stars = "â­â­â­â­â­"
            elif quality_score >= 85:
                stars = "â­â­â­â­"
            elif quality_score >= 75:
                stars = "â­â­â­"
            elif quality_score >= 65:
                stars = "â­â­"
            else:
                stars = "â­"

            url_config = {
                "url": source["url"],
                "name": f"{source['name']}{stars}"
            }
            multi_repo_config["urls"].append(url_config)

        # ä¿å­˜JSONæ–‡ä»¶
        output_file = os.path.join(self.output_dir, "onetv-api-movie.json")

        try:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(multi_repo_config, f, ensure_ascii=False, indent=4)

            print(f"âœ… å¤šä»“åº“é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
            print(f"ğŸ“Š åŒ…å« {len(top_sources)} ä¸ªä¼˜è´¨æº (ä» {total_sources} ä¸ªæºä¸­ç­›é€‰)")
            print(f"ğŸ† å¹³å‡è´¨é‡è¯„åˆ†: {sum(s['quality_score'] for s in top_sources) / len(top_sources):.1f}")

            # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
            categories = {}
            for source in top_sources:
                category = source.get("category", "æœªåˆ†ç±»")
                categories[category] = categories.get(category, 0) + 1
            print(f"ğŸ“‚ åˆ†ç±»ç»Ÿè®¡: {categories}")

            return output_file

        except Exception as e:
            print(f"âŒ ç”ŸæˆJSONæ–‡ä»¶å¤±è´¥: {str(e)}")
            return ""
    
    def generate_statistics(self, vod_data: Dict) -> Dict:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        valid_sources = vod_data.get("valid_sources", [])
        total_sources = vod_data.get("total_sources", 0)
        
        # åˆ†ç±»ç»Ÿè®¡
        categories = {}
        quality_distribution = {"ä¼˜ç§€(90+)": 0, "è‰¯å¥½(80-89)": 0, "åŠæ ¼(70-79)": 0}
        
        for source in valid_sources:
            # åˆ†ç±»ç»Ÿè®¡
            category = source.get("category", "æœªåˆ†ç±»")
            categories[category] = categories.get(category, 0) + 1
            
            # è´¨é‡åˆ†å¸ƒ
            score = source.get("quality_score", 0)
            if score >= 90:
                quality_distribution["ä¼˜ç§€(90+)"] += 1
            elif score >= 80:
                quality_distribution["è‰¯å¥½(80-89)"] += 1
            else:
                quality_distribution["åŠæ ¼(70-79)"] += 1
        
        # å“åº”æ—¶é—´ç»Ÿè®¡
        response_times = [s.get("response_time", 0) for s in valid_sources]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0
        
        statistics = {
            "summary": {
                "total_configured": total_sources,
                "valid_sources": len(valid_sources),
                "success_rate": f"{(len(valid_sources) / total_sources * 100):.1f}%" if total_sources > 0 else "0%",
                "average_quality_score": f"{vod_data.get('average_score', 0):.1f}",
                "average_response_time": f"{avg_response_time:.2f}s",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            "categories": categories,
            "quality_distribution": quality_distribution,
            "top_sources": sorted(valid_sources, key=lambda x: x.get("quality_score", 0), reverse=True)[:10]
        }
        
        return statistics
    
    def save_statistics(self, statistics: Dict) -> str:
        """ä¿å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats_file = os.path.join(self.output_dir, "vod_statistics.json")
        
        try:
            with open(stats_file, "w", encoding="utf-8") as f:
                json.dump(statistics, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_file}")
            return stats_file
            
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return ""


def process_vod_sources(vod_data: Dict) -> Dict:
    """å¤„ç†ç‚¹æ’­æºæ•°æ®çš„ä¸»å‡½æ•°"""
    processor = VODProcessor()
    
    # ç”ŸæˆJSONæ–‡ä»¶
    json_file = processor.generate_vod_json(vod_data)
    
    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    statistics = processor.generate_statistics(vod_data)
    stats_file = processor.save_statistics(statistics)
    
    return {
        "json_file": json_file,
        "statistics_file": stats_file,
        "statistics": statistics
    }
